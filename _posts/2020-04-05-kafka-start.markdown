---
layout: post
title:  "Kafka开篇分享"
description: Kafka的基本介绍
date:   2020-04-05 15:34:36 
categories: kafka
---

我们在学习中间件的时候，需要搞明白的是：

**1. 这款中间件，可以帮助我们解决哪些需求**

**2. 我们有什么样子的使用场景**

**3. 该中间件的解决方案是什么**

**4. 背后的原理是什么**

## 消息中间件的简单背景

### 单机： 订单出票 和 消耗库存

![image-20191129135014167](../../../assets/kafka/image-20191129135014167.png)

### 分布式

![image-20191129135238054](../../../assets/kafka/image-20191129135238054.png)

### 如果我们自己实现一个消息中间件

#### 基本需求

消息的发送和接收  

> NIO、序列化和反序列化、协议

消息模式

> push
>
> Pull

消息存储 

> 持久化。数据库存储（ActivityMQ）、文件存储（零拷贝、页缓存、磁盘、顺序存储）
>
> 非持久化。内存

是否支持跨语言

消息确认（确认机制，希望给业务提供的支持）

支持集群 -> master选举

#### 高级需求

消息是否支持有序(业务逻辑)

是否支持高并发和大数据存储(应用场景)

是否支持可靠性存储（副本机制）

是否支持多协议

>  其实从这种角度出发，我们可以大致摸到这种类型的中间件的重点在哪里。不同的实现框架有哪些侧重点
>
>  在接下来的学习中，也可以有侧重有思考。

### 消息中间件的发展

#### 开始

金融领域，金融分析师可以通过pub/sub订阅感兴趣的内容

TIB(T Information Bus)建立一套规则发布消息，消费者可以去订阅消息。

#### IBM MQ

IBM （websphere mq）用来在两个应用程序间进行通信

![image-20191201151659171](../../../assets/kafka/image-20191201151659171.png) 

#### MSMQ

![image-20191201153509767](../../../assets/kafka/image-20191201153509767.png)

#### JMS

2001年，JMS （Java Message Service）产生，是一个[Java平台](https://baike.baidu.com/item/Java平台)中关于面向[消息中间件](https://baike.baidu.com/item/消息中间件/5899771)（MOM）的[API](https://baike.baidu.com/item/API/10154)，用于在两个应用程序之间，或[分布式系统](https://baike.baidu.com/item/分布式系统/4905336)中发送消息，进行异步通信。Java消息服务是一个与具体平台无关的API，绝大多数MOM提供商都对JMS提供支持。

![image-20191201160659269](../../../assets/kafka/image-20191201160659269.png)

#### AMQP

AMQP （Advanced Message Queuing Protocol），一个提供统一消息服务的**应用层标准**的高级[消息](https://baike.baidu.com/item/消息/1619218)队列协议，是[应用层](https://baike.baidu.com/item/应用层/4329788)协议的一个开放标准，为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/[中间件](https://baike.baidu.com/item/中间件/452240)不同产品，不同的开发语言等条件的限制

### 为什么要引入MQ

- 解耦 + 异步通信（订单出票和消耗库存、影院组更新和活动影院组关联关系更新）

> 两个处理过程不属于同一个领域，没有必要做成实时。因此就可以通过MQ来做到解耦和异步通信。
>
> 订单出票和我们接收消息消费库存。 不是用来做分布式事务的，因为分布式事务，必须全部完成或者全部失败。其业务场景并不符合。

- 提高扩展性

> 扩展性的前提条件也是属于：A动作触发B动作，AB是可以拆分的，将来的其他动作也都是可以拆分的。

- 流量削峰

> 秒杀活动，一般会因为流量过大，导致流量暴增，应用挂掉。为了解决这个问题，一般需要在应用前端加入消息队列。1. 可以控制活动的任务，2. 可以缓解短时间内高流量压垮应用

### 引入MQ我们需要考虑什么

1. 消息传递路径变长，延时会增加
2. 上游无法感知下游的执行结果
3. 如何处理消息丢失的情况，补偿机制？
4. 是否需要考虑消息的顺序

不管怎么样，我们可以确认的一个准则是： **在需要实时结果的时候，我们不应该使用MQ**。

### 其他MQ组件

| MQ       | 特点                                      |
| -------- | ----------------------------------------- |
| Kafka    | 十万级、大数据标配、日志、可容忍丢失      |
| RabbitMQ | 万级、中小公司的选择、社区活跃， 支持AMQP |
| ActiveMQ | 万级、社区不活跃                          |
| RocketMQ | 十万级、丢失0容忍                         |



## Kafka基础介绍

### Kafka是什么

#### 一个定位： 流平台

**kafka 是一个分布式流平台**。用来构建实时数据管道和流应用。它具有横向**可扩展性**、**容错性**、**极快的速度**，并且在数千家公司的生产中应用。

> Kafka® is used for building **real-time data pipelines and streaming apps.** It is horizontally scalable, fault-tolerant, wicked fast, and runs in production in thousands of companies.

![image-20191201181049091](../../../assets/kafka/image-20191201181049091.png)

#### 三个关键能力

一个流平台，需要有三个关键能力：**

- PUBLISH & SUBSCRIBE：发布和订阅记录流，类似消息队列或者企业消息系统。
- STORE：以一种容错和耐用的方式保存记录流
- PROCESS：当记录流出现的时候处理他们。

#### 两个广泛应用场景

kafka通常用在两种比较广泛的应用场景。

1. 构建 `实时` 的流数据管道，在系统和应用之间 `可靠` 的传输数据
2. 构建实时的可以转换或者响应流数据的流应用

想了解kafka是怎么做到这些的，让我们自底向上的深入和探索kafka的能力

### Kafka的一些概念

#### 基本概念

首先先了解一些概念：

- kafka不论是在一台机器上还是多台服务器上，**都是一个集群**，可以扩展多个数据中心
- kafka**将流数据分类存储，这个分类就叫topics**
- 每一个记录都包含一个key,一个value,还有一个时间戳

#### 四类API

kafka有四类api:

1. Producer API 

2. Consumer API

3. Stream API  

    > 允许应用程序作为一个流处理器，从一个或者多个topics中消费，产生输出流到topics中。有效将输入流转换成输出流

4. Connector API

    > 可以构建和运行可重复使用的生产者和消费者，将kafka topics连接到已经存在的应用和数据系统中。 比如连接到一个关系数据库系统的connector可以捕捉所有针对某个表的变化。

![image-20191201181526678](../../../assets/kafka/image-20191201181526678.png)

在kafka里面，客户端与服务器端的交流使用的是TCP协议，kafka虽然只提供Java Client, 但其实也可以支持其他语言。

#### Topics And Logs

##### Topic

kafka提供给流记录的抽象概念是：【**<u>topic</u>**】。它是kafka中的一个核心抽象。

topic是一个流记录的分类或者种子名称。在kafka中，一个topic可以有多个消费者。

##### 分区和日志

对于每一个topic,kafka维护一个【 <u>**分区日志**</u>】， 如下图所示。

![image-20191201181702525](../../../assets/kafka/image-20191201181702525.png)

每一个分区都是一个**有序的、记录顺序不可更改的（记录被持续添加的）的一个结构化**的commit 日志。

**topic进行分区的目的有：**

**1. 日志不受单台服务器可承载的大小限制，允许日志的size超过单台服务器的大小。虽然仍然会有每个分区必须适合承载它的服务器的大小的限制，但一个topic可以有多个分区，因此topic可以处理任意数量的数据。**

**2. 从某种意义上来讲更像是并行的**

##### 位移

分区中的记录每一个被赋予了一个sequence id number用来唯一的标识分区中的每一个记录，这个序列号被称为【**<u>offset</u>】.**

##### 保留区间

kafka集群**可以配置一个保留区间，持久化的保存所有的发布的数据**——不管他们有没有被消费。如果保留区间为2天，那么一条记录在发布后的两天内都是可以被消费的，两天后这条记录将会被删除以释放空间。

那【**<u>保留区间</u>**】应该怎么设置呢？

那是不是将保留区间设置的越小越好呢，这样会少占用磁盘空间。

> **其实kafka的性能与数据大小成常数关系，所以保存数据很长时间也不成问题。**

但站在生成环境的角度，1:数据空间是需要成本的，2.很久之前的数据不一定有业务场景需要  3.保留区间太小可提供的错误处理弹性就越小。

既然kafka性能与数据大小是常数关系，因此保留区间可以在可承担成本内，根据业务需要进行设置。

![image-20191201182118836](../../../assets/kafka/image-20191201182118836.png)

**每一个consumer基本上持有的元数据信息只有：log中的该消费者的offset或者position。** 

##### 消费者初始控制offset

**这个offset被消费者控制：一般来讲，消费者会随着读取记录线性地增加offset。但其实因为位置是由消费者控制的，因此消费者可以以任何顺序消费记录。**比如：一个消费者可以重置offset到一些旧记录重新处理过去的数据，也可以直接跳到当前最新的记录。

这种特性的组合意味着： kafka的消费者实现的代价很便宜——他们可以随意的开始消费或者结束消费，而不会对集群或者其他消费者造成影响。比如，你可以使用命令行来为任何topic“tail”内容，而不改变已有消费者的消费内容。

#### Distribution分布式

日志中的分区**平均分布**在kakfa集群的服务器上，每一个服务器为一批分区处理数据和请求。 

##### 副本容错

每一个分区都有【<u>**副本**</u>】并且副本横跨在多台服务器上，这样可以容错。

##### leader和选举

每一个分区都有一台服务器作为**“leader”**节点，有0或多个服务器作为**“follow”**节点。**【leader处理该分区的所有的读写请求】**，而其他的follower节点只能被动的赋值主节点。

如果一个leader失败，其他的follower中的一个将会自动成为新的leader.

**每一个服务器都会是一些分区的leader和某些分区的follower，从而集群能够达到负载的均衡。**

####Geo-Replication

Kafka的镜像制作 为集群提供了geo-repilcation的支持。理解：geo-repilcation，基于地域的副本。如果不同的kafka集群称为不同的地域，则geo-repilcation为数据提供了跨集群的操作。

消息可以在多数据中心或者集群区域间复制。可以用作备份、恢复，也可以让数据离用户近一点，或者支持数据本地化的要求。

#### Producer

生产者将数据发布到topic中。

##### 分区发送策略

 **它需要在topic中选择将记录追加到哪个分区。可以使用Round-Robin 函数简单的均衡负载，也可以根据一些语义分区函数（如基于记录的key)。**在一秒内进行分区的场景用的更多。

#### Consumer

consumers会为自己设置一个消费组的lable。topic中的每个记录都会被送到每一个消费组的某个消费者实例上。 消费者实例可以是一些独立的处理器或者机器上。

![image-20191201182547163](../../../assets/kafka/image-20191201182547163.png)

对于kafka来说，一个消费组是一个集群还是一个单个进程，都只是发布订阅的语义，没有多余的含义。

##### 消费者分区分配策略

kafka的消费通过将分区分散到不同的消费者实例上完成，**每个消费者实例在任何时间点都是某一个分区的“公平共享”的唯一使用者。**

##### 再均衡

**这个维护组成员身份的任务由kafka协议动态处理。如果新实例加入该组，则他们会从该组的其他成员手中接管一些分区；如果一个实例死了，它的分区将分配给其余的实例。**

##### 分区有序性

**kafka只提供一个分区内的记录有序性，而不提供同一个topic不同分区间的有序。**分区有序性 + 使用key来分区数据 可以满足大多数应用程序的需要。然而，如果你想要topic有序，只能选择使用一个分区 + 一个消费组内只有一个实例的用法。

#### Multi-tenancy多租户

你可以将kafka部署为一个多租户解决方案。通过配置可以生产或者消费数据的topic来使能多租户。也有支持对配额的操作。管理员可以定义请求上的配额来控制被客户端使用的broker资源。更多信息见 [security documentation](https://kafka.apache.org/documentation/#security).

#### Guarantees

kafka为我们提供一下保证：

1. 一个生产者发送到一个分区的消息的顺序是它们被发送的顺序。即一个生产者生产了M1,M1两条消息，且M1先被发送，则M1的offset要小于M2。

2. 消费者看到的消息顺序就是它们被存储的顺序。

3. 一个topic如果有N个副本，我们可以容忍N-1个服务器失败而不损失任何记录



#### kafka的流概念与传统企业消息系统有什么区别

消息消费传统有两个模型：**队列和发布订阅**。

队列： 消费者池中的消费者从服务器端读取记录，每个记录被发送到他们中的一个。也被称为P2P（点对点）传输。

![image-20191205222935428](../../../assets/kafka/image-20191205222935428.png)

发布和订阅模式：记录会被广播到所有的消费者。 

![image-20191205222958214](../../../assets/kafka/image-20191205222958214.png)

https://blog.csdn.net/wqc19920906/article/details/82193316

| 模式                   | P2P点对点/队列                                       | 发布订阅                     | kafka                    |
| ---------------------- | ---------------------------------------------------- | ---------------------------- | ------------------------ |
| 伸缩                   | 一条消息只会发送给一个consumer允许对consumer实现扩容 | 无法实现伸缩                 | 消费组内的消费者可以伸缩 |
| 多消费者消费同一个消息 | 一条消息只会有一个消费者                             | 一条消息被广播到所有的消费者 | 广播消息至多个消费组     |

**kafka的优势是：每一个topic可以同时做到：动态扩容 + 多订阅者，而不用二选一。另外，kafka比起传统消息系统， 也有强的顺序保证。**

一个传统的队列顺序保存记录。如果多个消费者同时消费，则记录将会按照被保存的顺序被发送给消费者。但由于中间网络的原因，并不保证消息到达消费者实例的顺序还能一样。**这其实意味着消息的顺序在并行消费的过程中丢失了。**

如果处理   ——消息顺序在并行消费过程中丢失——的问题呢。

传统的消息系统通常使用**排他的消费者**的概念，即只允许一个进程消费队列来保证顺序性，然而这也意味着消息处理不在有并发性。

kafka选择了另外一种方式。**使用分区拥有并行的概念**，kafka可以同时提供顺序保证和在消费者之间的负载均衡。通过将一个topic中的某个分区交付给一个消费组内的某个消费者， **某个分区可以被组内唯一的一个消费者消费，因此有顺序的保证**。因为许多分区被消费者实例均衡的使用，所以也会有均衡的负载。

注意消费者实例不能多于分区的个数。

#### **Kafka As a storage system**

消息系统——允许发布消息和消费消息解耦的系统——都可以有效的作为飞行消息的存储系统。kafka不同的是：kafka是一个很好的存储系统。

1. 数据被写到磁盘上、并且被复制以容错。

2. kafka的磁盘结构可以动态伸缩。kafka的性能在：50Kb和50TB的时候是一样的。

认真的考虑日志存储和允许客户端控制读取位置的特点，kafka可以被认为**一个特殊的分布式文件系统，致力于高性能、低延迟提交日志系统、复制和传播**

更多的关于kafka的提交日志存储和副本设计，可以阅读 [this](https://kafka.apache.org/documentation/#design) page

#### **Kafka for Stream Processing**

仅仅读、写和保存流数据是不够的，目的是能够实时的处理流数据。

一个流处理这应该能够持续的从input topic中读取流数据，对数据加工处理，并持续地输出到output topic中。

![image-20191205223404305](image-20191205223404305.png)

比如：一个零售系统从topic中读取销售量和运输等信息，然后输出再订购和价格调整信息到output topic中。

可以使用Producer 和 Consumer API来构建一个简单的流处理系统，但针对于更复杂的场景，kafka提供了一个流API。流处理API为应用省去了聚合流数据和连接流数据的任务。

这解决了这类应用通常要面临的难题：处理无序的数据，在代码更改时重新处理输入、执行状态计算等

流处理API构建在kafka提升的原子能力上。使用producer 和 consumer 的API， 使用kafka来进行状态的存储，使用同样的组机制来为多个流处处理器实例进行容错。

#### **Putting the Pieces Together**

这种将“消息”，“存储”，“流处理”系统集成在一起的做法看起来不太常见，但是对于kafka——一个流平台来讲，是需要提供这些能力的

分布式文件系统如HDFS允许为需要批处理的数据提供存储。其他类似的系统也都是保存和处理过去的历史数据。

一个传统的消息系统允许你在订阅消息后处理将来可能到达的数据，基于这种方式构建的应用程序当数据到达的时候进行处理

kafka结合了这两种能力，而且这种结合是至关重要的——对于kafka作为一个流应用平台或者流数据管道

通过结合存储和低延迟订阅，流式应用程序可以以相同的方式处理过去和将来的数据。这是一个应用程序可以处理历史数据和存储数据，但当它到达最后一条记录时，它可以继续处理未来数据。**这是流处理的一个广义概念，包含批处理和消息驱动应用程序。**

---------大概这两个讲的都是kafka的结合能力

类似的，对于流数据管道，对实时时间的订阅组合是的kafka可以作为低延迟的数据库管道。另外可靠地存储数据的能力，使得kafka能够用于保证数据交付的关键数据或集成数据，也可以用于和离线系统的集成，这些离线系统可能只定期加载数据或者在维护时间内长时间停机。

流处理设施使数据到达时能够进行转换。

有关Kafka提供的保证、API和功能的更多信息，请参阅文档的其余部分。

# 参考文章

IBM websphere mq :

[IBM MQ 简单开发和应用](https://blog.csdn.net/lvshaorong/article/details/77188538)

[IBM Websphere MQ 简单概述](