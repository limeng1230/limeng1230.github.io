---
layout: post
title:  "Kafka可用性"
description: Kafka的性能和可靠性
date:   2020-05-01 15:34:36 
categories: kafka
---
## kafka性能

### 生产者的吞吐量

![image-20200429221404283](../../../assets/kafka/image-20200429221404283.png)

#### kafka的性能高

约80万records/sec。对于随机存储的数据系统（数据库、KV系统）来说，我们常见的吞吐量是5000-50000 qps, 和一个比较好的PRC可以接受和处理的速度差不多。但是kafka超越了这个数量。

两条原因：

>1. 线性磁盘IO。 线性磁盘IO，大约能够保证822 MB/sec的吞吐量。这实际上远远超出了我们仅使用1千兆网卡所能利用的范围。许多消息传递系统将持久性视为一个昂贵的附加操作，它会降低性能，应该只少量使用，但这是因为它们不能执行线性I/O。
>2. 在每一个阶段，我们都会将少量的数据批处理到更大的网络和磁盘I/O操作中。例如，在新的producer中，我们使用类似“group commit”的机制来确保在另一个I/O正在进行时发起的任何记录都被分组在一起。

#### 同步速度

从单个生产者 -> 单个生产者+3个同步副本 ， 吞吐量从82万到78万。几乎没有下降。做实验的人旨在告诉我们，kafka的同步是很快的。

### 存储量级是否会影响到生产者的吞吐量

许多消息传递系统的一个隐患是，只有当它们保留的数据可以放到内存的时候，它们才能正常工作。当数据备份时，它们的吞吐量会下降一个数量级（或更多），并且不会被消费（因此需要存储在磁盘上）。

这意味着，只要你的消费者保持正常，系统中的队列是空的，事情就可以正常运行，但一旦它们延迟，整个消息传递层就会将未使用的数据备份。备份会导致数据进入磁盘，进而导致性能下降。这意味着消息传递系统无法再跟上生成者的速度，或者备份，或者崩溃。这非常糟糕，因为在许多情况下，队列的全部目的是优雅地处理这样的情况。

由于Kafka始终保持消息，因此对于未使用的数据量，性能为O（1）。

![image-20200312204745437](../../../assets/kafka/image-20200312204745437.png)

做测试的人对于波动的解释：同步磁盘的操作，定期刷新数据.

1. 虽然消息写入是磁盘顺序写入，没有磁盘寻道的开销，但是如果针对每条消息都执行一次磁盘写入，则也会造成大量的磁盘IO，影响性能。
2. 所以在消息写入方面，broker基于MMAP技术，即内存映射文件，将消息先写入到操作系统的页缓存中，由页缓存直接映射到磁盘文件，不需要在用户空间和内核空间直接拷贝消息，所以也可以认为消息传输是发送在内存中的。
3. 由于是先将消息写入到操作系统的页缓存，而页缓存数据刷新同步sync到磁盘文件是由操作系统来控制的，即操作系统通过一个内核后台线程，每5秒检查一次是否需要将页缓存数据同步到磁盘文件，如果超过指定时间或者超过指定大小则将页缓存数据同步到磁盘。所以如果在刷新到磁盘文件之前broker机器宕机了，则会导致页缓存的数据丢失。
4. 使用页缓存的另外一个好处是，如果重启了kafka服务端（这个服务重启，而不是机器重启），页缓存中的数据还是可以继续使用的。

### 消费者的吞吐量

作者同样对单个消费者，多个消费者可以消费的记录做了一个对比测试，几乎接近线性的缩放比例（这并不奇怪，因为模型中的消耗是如此简单）

 使消费变得简单和容易是kafka很重要的一件事。一方面，副本本身就是消费者，因此使消费者简单会使复制简单。另外，这使得处理数据成为一种廉价的操作。

```scala
handleFetchRequest{
   if (fetchRequest.isFromFollower) {
     	.....
      } else {
        ....
      }
}
```

### 消息大小的影响

目的：看消息大小是否会影响到吞吐量。



![image-20200312205445335](../../../assets/kafka/image-20200312205445335.png)



我们每秒可以发送的原始记录数随着记录的增加而减少。但是，如果我们看MB/秒，我们会发现，随着消息变大，实际用户数据的总字节吞吐量会增加。

### 端到端的延迟

| 2毫秒（中位数）         |
| ----------------------- |
| 3毫秒（第99个百分位数） |
| 14毫秒（百分之99.9）    |

前面都是已经讨论了很多吞吐量，但是消息传递的延迟是多少？也就是说，我们发送给消费者的消息要花多长时间？对于此测试，我们将创建生产者和消费者，并反复计时生产者将消息发送到kafka集群然后被我们的消费者接收所花费的时间。

### 复现上面的测试

作者称主要只是使用了Kafka附带的预打包性能测试工具，并且大部分都使用服务器和客户机的默认配置。

## Kafka的可靠性

可靠性可以从两个方面看：

使用：使用者使用服务的可靠性

底层：中间件自己本身的可靠性

这次分享只关心使用角度的可靠性。

## 使用角度的可靠性

![kafka可靠性](../../../assets/kafka/kafka可靠性.png)

1. 消息发送
2. 消息接收
3. 消息存储

### 如何保证接收到了我发送的消息Kafka接收了？

> 第一步：按照实际需要 设置 不同的保证级别

![生产者](../../../assets/kafka/生产者.png)

> 第二步，我设置了ack=1, 但是 leader副本挂了、网络等原因，导致失败，怎么办?

retries（用来配置生产者重试的次数）和retry.backoff.ms（用来设定两次重试之间的间隔时间，避免无效的频繁重试）

retries的具体实现参考（Sender类）

什么是可重试的/临时性的异常： 网络抖动，leader副本选举等可恢复。

什么是不可重试的：消息的大小超过max.request.size

> 第三步，如果重试之后，仍然失败，怎么处理

可以采用同步或者异步的方式关心消息发送的结果。

### 如何保证我的消息Kafka可以存储起来？

**副本机制**

1、提供数据冗余

系统部分组件失效，系统依然能够继续运转，因而增加了整体可用性以及数据持久性

2、提供高伸缩性

支持横向扩展，能够通过增加机器的方式来提升读性能，进而提高读操作吞吐量

3、改善数据局部性

允许将数据放入与用户地理位置相近的地方，从而降低系统延时。

Kafka目前的副本机制，有两个能力：**数据冗余妨丢失，功能冗余提供备份**

#### 回顾下Kafka中的副本

Assigned Replicas ： 所有的副本

ISR（In-Sync Replicas，与 Leader 数据同步的 Replica）

OSR（Outof-Sync Replicas）

分区副本机制，使得kafka既可以提供**数据副本**妨丢失，也可以提供**服务副本做备份**.

##### 分区分配方法

> 1、 将所有Broker（假设共n个Broker）和待分配的Partition排序
> 2、 将第i个Partition分配到第（i mod n）个Broker上
> 3、 将第i个Partition的第j个Replica分配到第（(i + j) mode n）个Broker上

可参考kafka.admin.AdminUtils#assignReplicasToBrokersRackUnaware

##### 如何判断一个副本是否失效

初始情况下，所有的 Replica 都在 ISR 中，但在 Kafka 工作过程中，由于各种问题（网络、磁盘、内存）可能导致部分 Replica 的同步速度慢于参数 `replica.lag.time.max.ms` 指定的阈值，一旦出现这种情况，这部分 Replica 会被移出 ISR，降级至 OSR 中。

>  **replica.lag.time.max.ms**
>
>  数据类型为 Long，默认值为 10000，重要性为 High，官方解释如下：
>
>  If a follower hasn't sent any fetch requests or hasn't consumed up to the leaders log end offset for at least this time, the leader will remove the follower from ISR.

即在10s内，如果发生以下两种情况，一个副本就会被移除ISR

- 当一个副本没有发送任何 fetch request
- 没有消费到leader LEO

```scala
def getOutOfSyncReplicas(maxLagMs: Long): Set[Int] = {
    /**
     * If the follower already has the same leo as the leader, it will not be considered as out-of-sync,
     * otherwise there are two cases that will be handled here -
     * 1. Stuck followers: If the leo of the replica hasn't been updated for maxLagMs ms,
     *                     the follower is stuck and should be removed from the ISR
     * 2. Slow followers: If the replica has not read up to the leo within the last maxLagMs ms,
     *                    then the follower is lagging and should be removed from the ISR
     * Both these cases are handled by checking the lastCaughtUpTimeMs which represents
     * the last time when the replica was fully caught up. If either of the above conditions
     * is violated, that replica is considered to be out of sync
     *
     **/
    val candidateReplicaIds = inSyncReplicaIds - localBrokerId
    val currentTimeMs = time.milliseconds()
    val leaderEndOffset = localLogOrException.logEndOffset
    candidateReplicaIds.filter(replicaId => isFollowerOutOfSync(replicaId, leaderEndOffset, currentTimeMs, maxLagMs))
  }
```

#### ISR的伸缩

两个定时任务检测是否需要缩减或者扩充ISR集合

Isr-expiration: 周期性( [replica.lag.time.max.ms](http://replica.lag.time.max.ms) 的一半）的检测每个分区是否需要缩减ISR集合

Isr-change-propagation：向其他的broker传播ISR的变动消息

当leader处理完来自follow的fetch请求后，会更新对应Replica对象的_lastCaughtUpTimeMs，然后判断是否要把此Replica加进ISR中(可能之前这个replica没在ISR中)，最后尝试推进HW。

![ISR的伸缩](../../../assets/kafka/ISR的伸缩.jpg)

```text
1. follower fetch时leader副本更新follower状态， 代码入口kafka.server.KafkaApis#handleFetchRequest
2. 定时任务检查是否有ISR集合，见kafka.server.ReplicaManager#maybeShrinkIsr
3. kafka控制器会接收到ZK的IsrChangeNotification变更，处理processIsrChangeNotification
```

#### ISR与使用者有什么关系

不能排除leader节点宕机的情况，因此存在leader选举机制。每个follower副本的状态都不一样，如果一个严重落后的follower副本被选举为leader。 那么就会加剧**消息丢失**的情况。因此从ISR中选举leader，则是一个比较好的权衡策略。

`unclean.leader.election.enable=false`

#### 回顾下LEO与HW

![image-20200430114002964](../../../assets/kafka/image-20200430114002964.png)

####leader宕机情况下的数据丢失和不一致的场景

##### LEO与HW的推进

![LEO与HW的更新](../../../assets/kafka/LEO与HW的更新.jpg)

##### 基于HW同步，造成数据丢失和数据不一致场景

![数据丢失的场景](../../../assets/kafka/数据丢失的场景.jpg)

![数据不一致的场景](../../../assets/kafka/数据不一致的场景.png)



#### 使用领导者纪元解决丢失和不一致的问题

0.11.0.0版本之后

![纪元-应对数据丢失和不一致的场景](../../../assets/kafka/纪元-应对数据丢失和不一致的场景.png)

![纪元-应对不一致的场景](../../../assets/kafka/纪元-应对不一致的场景.png)

>
>
>核心： 利用HW 和 LEO 的错误来缩小问题范围。
>
>当follower选举为leader时：
>
>1. 如果 HW=21  <  LEO=23  <= 原leader的HW=23 < 原leader的LEO=30，就会造成数据丢失的情况。
>
>    1. 如果基于HW截断，就会丢失【21,30】之间的数据
>
>    2. 如果基于领导者纪元判断，会丢失【23，30】的数据
>
>2. （follower被选举为节点是，le0=23）如果HW=30 < LEO=30 <= 原leader的HW=30 < 原leader的LEO=30
>
>    1. 如果基于HW截断，就会导致【23，30】之间的数据不一致
>
>    2. 如果基于领导者纪元判断，不会导致数据不一致。

总结：

kafka 利用：副本机制、基于leaderEpoach来尽量解决数据丢失和不一致。

另外，如性能部分所说kafka利用的页缓存技术会受到操作系统的影响。因此broker提供了 [log.flush.interval.ms](http://log.flush.interval.ms) 和log.flush.interval.messages用来调整同步刷盘的策略



### 如何保证消费者成功消费到了我的数据

enable.auto.commit =false手动提交，避免重复消费和消息丢失的问题

## 参考文档

[kafka的性能](https://engineering.linkedin.com/kafka/benchmarking-apache-kafka-2-million-writes-second-three-cheap-machines?spm=a2c4e.10696291.0.0.6cdb19a4MXTpcQ)

[组提交](https://www.cnblogs.com/cchust/p/4439107.html)

[kafka的消息存储](https://www.cnblogs.com/monkeyteng/p/10221291.html)

[副本管理器](https://www.jianshu.com/p/93277e510ca3)

[kafka的高可用](https://blog.51cto.com/13525470/2315452?cid=723173)

[kafka解析之失效副本](https://www.jianshu.com/p/aed1326880f1)