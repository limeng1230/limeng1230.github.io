I"Z<h1 id="kafka开篇分享">Kafka开篇分享</h1>

<h2 id="序言">序言</h2>

<p>我们在学习中间件的时候，需要搞明白的是：</p>

<p><strong>1. 这款中间件，可以帮助我们解决哪些需求</strong></p>

<p><strong>2. 我们有什么样子的使用场景</strong></p>

<p><strong>3. 该中间件的解决方案是什么</strong></p>

<p><strong>4. 背后的原理是什么</strong></p>

<h2 id="消息中间件的简单背景">消息中间件的简单背景</h2>

<h3 id="单机-订单出票-和-消耗库存">单机： 订单出票 和 消耗库存</h3>

<p><img src="../../../assets/kafka/image-20191129135014167.png" alt="image-20191129135014167" /></p>

<h3 id="分布式">分布式</h3>

<p><img src="../../../assets/kafka/image-20191129135238054.png" alt="image-20191129135238054" /></p>

<h3 id="如果我们自己实现一个消息中间件">如果我们自己实现一个消息中间件</h3>

<h4 id="基本需求">基本需求</h4>

<p>消息的发送和接收</p>

<blockquote>
  <p>NIO、序列化和反序列化、协议</p>
</blockquote>

<p>消息模式</p>

<blockquote>
  <p>push</p>

  <p>Pull</p>
</blockquote>

<p>消息存储</p>

<blockquote>
  <p>持久化。数据库存储（ActivityMQ）、文件存储（零拷贝、页缓存、磁盘、顺序存储）</p>

  <p>非持久化。内存</p>
</blockquote>

<p>是否支持跨语言</p>

<p>消息确认（确认机制，希望给业务提供的支持）</p>

<p>支持集群 -&gt; master选举</p>

<h4 id="高级需求">高级需求</h4>

<p>消息是否支持有序(业务逻辑)</p>

<p>是否支持高并发和大数据存储(应用场景)</p>

<p>是否支持可靠性存储（副本机制）</p>

<p>是否支持多协议</p>

<blockquote>
  <p>其实从这种角度出发，我们可以大致摸到这种类型的中间件的重点在哪里。不同的实现框架有哪些侧重点</p>

  <p>在接下来的学习中，也可以有侧重有思考。</p>
</blockquote>

<h3 id="消息中间件的发展">消息中间件的发展</h3>

<h4 id="开始">开始</h4>

<p>金融领域，金融分析师可以通过pub/sub订阅感兴趣的内容</p>

<p>TIB(T Information Bus)建立一套规则发布消息，消费者可以去订阅消息。</p>

<h4 id="ibm-mq">IBM MQ</h4>

<p>IBM （websphere mq）用来在两个应用程序间进行通信</p>

<p><img src="../../../assets/kafka/image-20191201151659171.png" alt="image-20191201151659171" /></p>

<h4 id="msmq">MSMQ</h4>

<p><img src="../../../assets/kafka/image-20191201153509767.png" alt="image-20191201153509767" /></p>

<h4 id="jms">JMS</h4>

<p>2001年，JMS （Java Message Service）产生，是一个<a href="https://baike.baidu.com/item/Java平台">Java平台</a>中关于面向<a href="https://baike.baidu.com/item/消息中间件/5899771">消息中间件</a>（MOM）的<a href="https://baike.baidu.com/item/API/10154">API</a>，用于在两个应用程序之间，或<a href="https://baike.baidu.com/item/分布式系统/4905336">分布式系统</a>中发送消息，进行异步通信。Java消息服务是一个与具体平台无关的API，绝大多数MOM提供商都对JMS提供支持。</p>

<p><img src="../../../assets/kafka/image-20191201160659269.png" alt="image-20191201160659269" /></p>

<h4 id="amqp">AMQP</h4>

<p>AMQP （Advanced Message Queuing Protocol），一个提供统一消息服务的<strong>应用层标准</strong>的高级<a href="https://baike.baidu.com/item/消息/1619218">消息</a>队列协议，是<a href="https://baike.baidu.com/item/应用层/4329788">应用层</a>协议的一个开放标准，为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/<a href="https://baike.baidu.com/item/中间件/452240">中间件</a>不同产品，不同的开发语言等条件的限制</p>

<h3 id="为什么要引入mq">为什么要引入MQ</h3>

<ul>
  <li>解耦 + 异步通信（订单出票和消耗库存、影院组更新和活动影院组关联关系更新）</li>
</ul>

<blockquote>
  <p>两个处理过程不属于同一个领域，没有必要做成实时。因此就可以通过MQ来做到解耦和异步通信。</p>

  <p>订单出票和我们接收消息消费库存。 不是用来做分布式事务的，因为分布式事务，必须全部完成或者全部失败。其业务场景并不符合。</p>
</blockquote>

<ul>
  <li>提高扩展性</li>
</ul>

<blockquote>
  <p>扩展性的前提条件也是属于：A动作触发B动作，AB是可以拆分的，将来的其他动作也都是可以拆分的。</p>
</blockquote>

<ul>
  <li>流量削峰</li>
</ul>

<blockquote>
  <p>秒杀活动，一般会因为流量过大，导致流量暴增，应用挂掉。为了解决这个问题，一般需要在应用前端加入消息队列。1. 可以控制活动的任务，2. 可以缓解短时间内高流量压垮应用</p>
</blockquote>

<h3 id="引入mq我们需要考虑什么">引入MQ我们需要考虑什么</h3>

<ol>
  <li>消息传递路径变长，延时会增加</li>
  <li>上游无法感知下游的执行结果</li>
  <li>如何处理消息丢失的情况，补偿机制？</li>
  <li>是否需要考虑消息的顺序</li>
</ol>

<p>不管怎么样，我们可以确认的一个准则是： <strong>在需要实时结果的时候，我们不应该使用MQ</strong>。</p>

<h3 id="其他mq组件">其他MQ组件</h3>

<table>
  <thead>
    <tr>
      <th>MQ</th>
      <th>特点</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Kafka</td>
      <td>十万级、大数据标配、日志、可容忍丢失</td>
    </tr>
    <tr>
      <td>RabbitMQ</td>
      <td>万级、中小公司的选择、社区活跃， 支持AMQP</td>
    </tr>
    <tr>
      <td>ActiveMQ</td>
      <td>万级、社区不活跃</td>
    </tr>
    <tr>
      <td>RocketMQ</td>
      <td>十万级、丢失0容忍</td>
    </tr>
  </tbody>
</table>

<h2 id="kafka基础介绍">Kafka基础介绍</h2>

<h3 id="kafka是什么">Kafka是什么</h3>

<h4 id="一个定位-流平台">一个定位： 流平台</h4>

<p><strong>kafka 是一个分布式流平台</strong>。用来构建实时数据管道和流应用。它具有横向<strong>可扩展性</strong>、<strong>容错性</strong>、<strong>极快的速度</strong>，并且在数千家公司的生产中应用。</p>

<blockquote>
  <p>Kafka® is used for building <strong>real-time data pipelines and streaming apps.</strong> It is horizontally scalable, fault-tolerant, wicked fast, and runs in production in thousands of companies.</p>
</blockquote>

<p><img src="../../../assets/kafka/image-20191201181049091.png" alt="image-20191201181049091" /></p>

<h4 id="三个关键能力">三个关键能力</h4>

<p>一个流平台，需要有三个关键能力：**</p>

<ul>
  <li>PUBLISH &amp; SUBSCRIBE：发布和订阅记录流，类似消息队列或者企业消息系统。</li>
  <li>STORE：以一种容错和耐用的方式保存记录流</li>
  <li>PROCESS：当记录流出现的时候处理他们。</li>
</ul>

<h4 id="两个广泛应用场景">两个广泛应用场景</h4>

<p>kafka通常用在两种比较广泛的应用场景。</p>

<ol>
  <li>构建 <code class="highlighter-rouge">实时</code> 的流数据管道，在系统和应用之间 <code class="highlighter-rouge">可靠</code> 的传输数据</li>
  <li>构建实时的可以转换或者响应流数据的流应用</li>
</ol>

<p>想了解kafka是怎么做到这些的，让我们自底向上的深入和探索kafka的能力</p>

<h3 id="kafka的一些概念">Kafka的一些概念</h3>

<h4 id="基本概念">基本概念</h4>

<p>首先先了解一些概念：</p>

<ul>
  <li>kafka不论是在一台机器上还是多台服务器上，<strong>都是一个集群</strong>，可以扩展多个数据中心</li>
  <li>kafka<strong>将流数据分类存储，这个分类就叫topics</strong></li>
  <li>每一个记录都包含一个key,一个value,还有一个时间戳</li>
</ul>

<h4 id="四类api">四类API</h4>

<p>kafka有四类api:</p>

<ol>
  <li>
    <p>Producer API</p>
  </li>
  <li>
    <p>Consumer API</p>
  </li>
  <li>
    <p>Stream API</p>

    <blockquote>
      <p>允许应用程序作为一个流处理器，从一个或者多个topics中消费，产生输出流到topics中。有效将输入流转换成输出流</p>
    </blockquote>
  </li>
  <li>
    <p>Connector API</p>

    <blockquote>
      <p>可以构建和运行可重复使用的生产者和消费者，将kafka topics连接到已经存在的应用和数据系统中。 比如连接到一个关系数据库系统的connector可以捕捉所有针对某个表的变化。</p>
    </blockquote>
  </li>
</ol>

<p><img src="../../../assets/kafka/image-20191201181526678.png" alt="image-20191201181526678" /></p>

<p>在kafka里面，客户端与服务器端的交流使用的是TCP协议，kafka虽然只提供Java Client, 但其实也可以支持其他语言。</p>

<h4 id="topics-and-logs">Topics And Logs</h4>

<h5 id="topic">Topic</h5>

<p>kafka提供给流记录的抽象概念是：【<strong><u>topic</u></strong>】。它是kafka中的一个核心抽象。</p>

<p>topic是一个流记录的分类或者种子名称。在kafka中，一个topic可以有多个消费者。</p>

<h5 id="分区和日志">分区和日志</h5>

<p>对于每一个topic,kafka维护一个【 <u>**分区日志**</u>】， 如下图所示。</p>

<p><img src="../../../assets/kafka/image-20191201181702525.png" alt="image-20191201181702525" /></p>

<p>每一个分区都是一个<strong>有序的、记录顺序不可更改的（记录被持续添加的）的一个结构化</strong>的commit 日志。</p>

<p><strong>topic进行分区的目的有：</strong></p>

<p><strong>1. 日志不受单台服务器可承载的大小限制，允许日志的size超过单台服务器的大小。虽然仍然会有每个分区必须适合承载它的服务器的大小的限制，但一个topic可以有多个分区，因此topic可以处理任意数量的数据。</strong></p>

<p><strong>2. 从某种意义上来讲更像是并行的</strong></p>

<h5 id="位移">位移</h5>

<p>分区中的记录每一个被赋予了一个sequence id number用来唯一的标识分区中的每一个记录，这个序列号被称为【<strong><u>offset</u>】.</strong></p>

<h5 id="保留区间">保留区间</h5>

<p>kafka集群<strong>可以配置一个保留区间，持久化的保存所有的发布的数据</strong>——不管他们有没有被消费。如果保留区间为2天，那么一条记录在发布后的两天内都是可以被消费的，两天后这条记录将会被删除以释放空间。</p>

<p>那【<strong><u>保留区间</u></strong>】应该怎么设置呢？</p>

<p>那是不是将保留区间设置的越小越好呢，这样会少占用磁盘空间。</p>

<blockquote>
  <p><strong>其实kafka的性能与数据大小成常数关系，所以保存数据很长时间也不成问题。</strong></p>
</blockquote>

<p>但站在生成环境的角度，1:数据空间是需要成本的，2.很久之前的数据不一定有业务场景需要  3.保留区间太小可提供的错误处理弹性就越小。</p>

<p>既然kafka性能与数据大小是常数关系，因此保留区间可以在可承担成本内，根据业务需要进行设置。</p>

<p><img src="../../../assets/kafka/image-20191201182118836.png" alt="image-20191201182118836" /></p>

<p><strong>每一个consumer基本上持有的元数据信息只有：log中的该消费者的offset或者position。</strong></p>

<h5 id="消费者初始控制offset">消费者初始控制offset</h5>

<p><strong>这个offset被消费者控制：一般来讲，消费者会随着读取记录线性地增加offset。但其实因为位置是由消费者控制的，因此消费者可以以任何顺序消费记录。</strong>比如：一个消费者可以重置offset到一些旧记录重新处理过去的数据，也可以直接跳到当前最新的记录。</p>

<p>这种特性的组合意味着： kafka的消费者实现的代价很便宜——他们可以随意的开始消费或者结束消费，而不会对集群或者其他消费者造成影响。比如，你可以使用命令行来为任何topic“tail”内容，而不改变已有消费者的消费内容。</p>

<h4 id="distribution分布式">Distribution分布式</h4>

<p>日志中的分区<strong>平均分布</strong>在kakfa集群的服务器上，每一个服务器为一批分区处理数据和请求。</p>

<h5 id="副本容错">副本容错</h5>

<p>每一个分区都有【<u>**副本**</u>】并且副本横跨在多台服务器上，这样可以容错。</p>

<h5 id="leader和选举">leader和选举</h5>

<p>每一个分区都有一台服务器作为<strong>“leader”</strong>节点，有0或多个服务器作为<strong>“follow”</strong>节点。<strong>【leader处理该分区的所有的读写请求】</strong>，而其他的follower节点只能被动的赋值主节点。</p>

<p>如果一个leader失败，其他的follower中的一个将会自动成为新的leader.</p>

<p><strong>每一个服务器都会是一些分区的leader和某些分区的follower，从而集群能够达到负载的均衡。</strong></p>

<p>####Geo-Replication</p>

<p>Kafka的镜像制作 为集群提供了geo-repilcation的支持。理解：geo-repilcation，基于地域的副本。如果不同的kafka集群称为不同的地域，则geo-repilcation为数据提供了跨集群的操作。</p>

<p>消息可以在多数据中心或者集群区域间复制。可以用作备份、恢复，也可以让数据离用户近一点，或者支持数据本地化的要求。</p>

<h4 id="producer">Producer</h4>

<p>生产者将数据发布到topic中。</p>

<h5 id="分区发送策略">分区发送策略</h5>

<p><strong>它需要在topic中选择将记录追加到哪个分区。可以使用Round-Robin 函数简单的均衡负载，也可以根据一些语义分区函数（如基于记录的key)。</strong>在一秒内进行分区的场景用的更多。</p>

<h4 id="consumer">Consumer</h4>

<p>consumers会为自己设置一个消费组的lable。topic中的每个记录都会被送到每一个消费组的某个消费者实例上。 消费者实例可以是一些独立的处理器或者机器上。</p>

<p><img src="../../../assets/kafka/image-20191201182547163.png" alt="image-20191201182547163" /></p>

<p>对于kafka来说，一个消费组是一个集群还是一个单个进程，都只是发布订阅的语义，没有多余的含义。</p>

<h5 id="消费者分区分配策略">消费者分区分配策略</h5>

<p>kafka的消费通过将分区分散到不同的消费者实例上完成，<strong>每个消费者实例在任何时间点都是某一个分区的“公平共享”的唯一使用者。</strong></p>

<h5 id="再均衡">再均衡</h5>

<p><strong>这个维护组成员身份的任务由kafka协议动态处理。如果新实例加入该组，则他们会从该组的其他成员手中接管一些分区；如果一个实例死了，它的分区将分配给其余的实例。</strong></p>

<h5 id="分区有序性">分区有序性</h5>

<p><strong>kafka只提供一个分区内的记录有序性，而不提供同一个topic不同分区间的有序。</strong>分区有序性 + 使用key来分区数据 可以满足大多数应用程序的需要。然而，如果你想要topic有序，只能选择使用一个分区 + 一个消费组内只有一个实例的用法。</p>

<h4 id="multi-tenancy多租户">Multi-tenancy多租户</h4>

<p>你可以将kafka部署为一个多租户解决方案。通过配置可以生产或者消费数据的topic来使能多租户。也有支持对配额的操作。管理员可以定义请求上的配额来控制被客户端使用的broker资源。更多信息见 <a href="https://kafka.apache.org/documentation/#security">security documentation</a>.</p>

<h4 id="guarantees">Guarantees</h4>

<p>kafka为我们提供一下保证：</p>

<ol>
  <li>
    <p>一个生产者发送到一个分区的消息的顺序是它们被发送的顺序。即一个生产者生产了M1,M1两条消息，且M1先被发送，则M1的offset要小于M2。</p>
  </li>
  <li>
    <p>消费者看到的消息顺序就是它们被存储的顺序。</p>
  </li>
  <li>
    <p>一个topic如果有N个副本，我们可以容忍N-1个服务器失败而不损失任何记录</p>
  </li>
</ol>

<h4 id="kafka的流概念与传统企业消息系统有什么区别">kafka的流概念与传统企业消息系统有什么区别</h4>

<p>消息消费传统有两个模型：<strong>队列和发布订阅</strong>。</p>

<p>队列： 消费者池中的消费者从服务器端读取记录，每个记录被发送到他们中的一个。也被称为P2P（点对点）传输。</p>

<p><img src="../../../assets/kafka/image-20191205222935428.png" alt="image-20191205222935428" /></p>

<p>发布和订阅模式：记录会被广播到所有的消费者。</p>

<p><img src="../../../assets/kafka/image-20191205222958214.png" alt="image-20191205222958214" /></p>

<p>https://blog.csdn.net/wqc19920906/article/details/82193316</p>

<table>
  <thead>
    <tr>
      <th>模式</th>
      <th>P2P点对点/队列</th>
      <th>发布订阅</th>
      <th>kafka</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>伸缩</td>
      <td>一条消息只会发送给一个consumer允许对consumer实现扩容</td>
      <td>无法实现伸缩</td>
      <td>消费组内的消费者可以伸缩</td>
    </tr>
    <tr>
      <td>多消费者消费同一个消息</td>
      <td>一条消息只会有一个消费者</td>
      <td>一条消息被广播到所有的消费者</td>
      <td>广播消息至多个消费组</td>
    </tr>
  </tbody>
</table>

<p><strong>kafka的优势是：每一个topic可以同时做到：动态扩容 + 多订阅者，而不用二选一。另外，kafka比起传统消息系统， 也有强的顺序保证。</strong></p>

<p>一个传统的队列顺序保存记录。如果多个消费者同时消费，则记录将会按照被保存的顺序被发送给消费者。但由于中间网络的原因，并不保证消息到达消费者实例的顺序还能一样。<strong>这其实意味着消息的顺序在并行消费的过程中丢失了。</strong></p>

<p>如果处理   ——消息顺序在并行消费过程中丢失——的问题呢。</p>

<p>传统的消息系统通常使用<strong>排他的消费者</strong>的概念，即只允许一个进程消费队列来保证顺序性，然而这也意味着消息处理不在有并发性。</p>

<p>kafka选择了另外一种方式。<strong>使用分区拥有并行的概念</strong>，kafka可以同时提供顺序保证和在消费者之间的负载均衡。通过将一个topic中的某个分区交付给一个消费组内的某个消费者， <strong>某个分区可以被组内唯一的一个消费者消费，因此有顺序的保证</strong>。因为许多分区被消费者实例均衡的使用，所以也会有均衡的负载。</p>

<p>注意消费者实例不能多于分区的个数。</p>

<h4 id="kafka-as-a-storage-system"><strong>Kafka As a storage system</strong></h4>

<p>消息系统——允许发布消息和消费消息解耦的系统——都可以有效的作为飞行消息的存储系统。kafka不同的是：kafka是一个很好的存储系统。</p>

<ol>
  <li>
    <p>数据被写到磁盘上、并且被复制以容错。</p>
  </li>
  <li>
    <p>kafka的磁盘结构可以动态伸缩。kafka的性能在：50Kb和50TB的时候是一样的。</p>
  </li>
</ol>

<p>认真的考虑日志存储和允许客户端控制读取位置的特点，kafka可以被认为<strong>一个特殊的分布式文件系统，致力于高性能、低延迟提交日志系统、复制和传播</strong></p>

<p>更多的关于kafka的提交日志存储和副本设计，可以阅读 <a href="https://kafka.apache.org/documentation/#design">this</a> page</p>

<h4 id="kafka-for-stream-processing"><strong>Kafka for Stream Processing</strong></h4>

<p>仅仅读、写和保存流数据是不够的，目的是能够实时的处理流数据。</p>

<p>一个流处理这应该能够持续的从input topic中读取流数据，对数据加工处理，并持续地输出到output topic中。</p>

<p><img src="image-20191205223404305.png" alt="image-20191205223404305" /></p>

<p>比如：一个零售系统从topic中读取销售量和运输等信息，然后输出再订购和价格调整信息到output topic中。</p>

<p>可以使用Producer 和 Consumer API来构建一个简单的流处理系统，但针对于更复杂的场景，kafka提供了一个流API。流处理API为应用省去了聚合流数据和连接流数据的任务。</p>

<p>这解决了这类应用通常要面临的难题：处理无序的数据，在代码更改时重新处理输入、执行状态计算等</p>

<p>流处理API构建在kafka提升的原子能力上。使用producer 和 consumer 的API， 使用kafka来进行状态的存储，使用同样的组机制来为多个流处处理器实例进行容错。</p>

<h4 id="putting-the-pieces-together"><strong>Putting the Pieces Together</strong></h4>

<p>这种将“消息”，“存储”，“流处理”系统集成在一起的做法看起来不太常见，但是对于kafka——一个流平台来讲，是需要提供这些能力的</p>

<p>分布式文件系统如HDFS允许为需要批处理的数据提供存储。其他类似的系统也都是保存和处理过去的历史数据。</p>

<p>一个传统的消息系统允许你在订阅消息后处理将来可能到达的数据，基于这种方式构建的应用程序当数据到达的时候进行处理</p>

<p>kafka结合了这两种能力，而且这种结合是至关重要的——对于kafka作为一个流应用平台或者流数据管道</p>

<p>通过结合存储和低延迟订阅，流式应用程序可以以相同的方式处理过去和将来的数据。这是一个应用程序可以处理历史数据和存储数据，但当它到达最后一条记录时，它可以继续处理未来数据。<strong>这是流处理的一个广义概念，包含批处理和消息驱动应用程序。</strong></p>

<p>———大概这两个讲的都是kafka的结合能力</p>

<p>类似的，对于流数据管道，对实时时间的订阅组合是的kafka可以作为低延迟的数据库管道。另外可靠地存储数据的能力，使得kafka能够用于保证数据交付的关键数据或集成数据，也可以用于和离线系统的集成，这些离线系统可能只定期加载数据或者在维护时间内长时间停机。</p>

<p>流处理设施使数据到达时能够进行转换。</p>

<p>有关Kafka提供的保证、API和功能的更多信息，请参阅文档的其余部分。</p>

<h1 id="参考文章">参考文章</h1>

<p>IBM websphere mq :</p>

<p><a href="https://blog.csdn.net/lvshaorong/article/details/77188538">IBM MQ 简单开发和应用</a></p>

<p>[IBM Websphere MQ 简单概述](</p>
:ET